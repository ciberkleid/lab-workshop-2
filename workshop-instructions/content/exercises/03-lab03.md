# Lift & Shift the Color Application to Kubernetes - Step 1

The color application was written in 2018 and has not been updated since then, hence it uses older versions of Spring Boot, Spring Cloud, and other dependencies. 
It represents a "heritage" application - an existing application that is presumably running in production and is satisfying business needs. 
However, the company is modernizing infrastructure, and operational benefit can be gained from running the application on Kubernetes.

Throughout the following exercises, you will "lift and shift" the color application to Kubernetes, with minimal changes. 
The first step is to package the applications as container images.

## Container images

The apps cannot be deployed as plain .class or .jar files on Kubernetes. 
Instead, each application, along with all of its dependencies - including all Spring and other supporting libraries, the JRE, and the OS filesystem itself - must be packaged into a bundle that adheres to a standard format (Docker or OCI, which stands for Open Container Initiative). 
The container image is, hence, a standardized, complete, self-contained, executable bundle. 
It is immutable, meaning it cannot be changed. 
Container images provide operational simplicity because they alleviate the burden of having to prepare or maintain dependencies on the target runtime environment. 
They make applications easily portable across any runtime that supports Docker or OCI images, and they enable any configuration, such as environment variables, that should be constant across environments to be packaged into the application, hence providing opportunities to better secure the application.

There are several ways to build container images. 
Dockerfile is the oldest approach. 
A Dockerfile is a script created using Dockerfile instructions. 
Since it is a plain text file that uses a simple syntax, it serves as a transparent record of the software that has been installed into the image, and it can be saved to a version control system, along with your application code. 
Dockerfiles are powerful because they can be used for any kind of application.

## Build container images with Dockerfile

Copy the following code to the Dockerfile. 
Notice that it uses two "build stages". 
In the first, it uses a JDK 8 image that is publicly available on Docker Hub. 
It installs maven and builds the app. 
In the second stage, it uses a different base image with only the JRE in it, since the JDK and maven are not needed at runtime, and it copies the executable jar to it. 
It sets the runtime user to a non-root user for security purposes, and it declares the start command that should be executed when a container is instantiated from this image.

Create a Dockerfile for the color service.

```editor:append-lines-to-file
file: ~/color-app/Dockerfile
text: |
        FROM adoptopenjdk:11-jdk-hotspot AS build
        RUN apt-get update && apt-get install -y --no-install-recommends \
            maven=3.6* \
        && apt-get clean \
        && rm -rf /var/lib/apt/lists/*
        WORKDIR /workspace
        COPY pom.xml .
        RUN mvn dependency:go-offline
        COPY src/ src/
        RUN mvn clean package -DskipTests -Dspring.cloud.contract.verifier.skip=true
        
        FROM adoptopenjdk:11-jre-hotspot
        WORKDIR /workspace
        COPY --from=build /workspace/target/*.jar app.jar
        USER 1002
        CMD ["java", "-jar", "app.jar"]
```

To execute the Dockerfile, use the `docker` CLI to communicate with the docker daemon.
```execute-1
docker build blueorgreenservice -f Dockerfile -t blueorgreenservice:df
```

Follow along in the output as each Docker instruction is executed. 
Each instruction creates a layer in the image. 
You can think of layers as analogous to `git commits` in a git repo. 
Each committed layer adds changes as a single event that are discrete from the layers before it. 
If the Dockerfile is executed again and there have been no changes to any of the instructions or to any of the files being copied into the image, then the layers are reused, not recreated.

The same Dockerfile can be used to build the rest of the applications. 
This is convenient, but it's also worth pointing out some drawbacks of Dockerfiles.

The Dockerfile you use here is a relatively simple Dockerfile, but every line represents a decision - good or bad - made by the Dockerfile author (use a two-stage approach, choice of base images and granularity of version tag, the precise syntax of the maven installation instruction, handling dependencies first and separately from source code, copying the packed jar to the runtime image as a single layer...).
Omissions also represent Dockerfile author decisions (e.g. no .dockerignore file, no LABELs, etc).

Some of these decisions are specific to Java.
If the author wanted to build a Golang app, for example, they would need to make (and maintain) a new set of decisions.
In any case, the full burden of responsibility for ensuring this Dockerfile implements best practices for efficiency, security, supportability, etc falls on the Dockerfile author.

In addition, short of copying and pasting Dockerfiles into other app repos, there is no formalized mechanism for re-using or sharing Dockerfiles.
There is also no formalized mechanism for managing Dockerfiles at enterprise-scale, where challenges of support, security, governance and transparency become critically important.

A final drawback with Dockerfiles is that a change to any layer invalidates all remaining layers from being reused as cache. 
This means that if you change the base image or the version of maven, for example, but you don't make any changes to the code, the `docker build` process will "bust the cache" at the changed layer and will re-download all maven dependencies and re-build the .jar file. 
It is more desirable - for efficiency, security, and predictability - not to rebuild artifacts or layers that have not changed, but Dockerfile is only so efficient at doing so.

Alternative tools provide higher-level abstractions with very interesting advantages as compared to Dockerfile. 
In the next step, you will explore one such option: Cloud Native Buildpacks using Paketo Buildpacks.

## Build container images with Cloud Native Buildpacks & Paketo Buildpacks

Cloud Native Buildpacks (_CNB_, or _buildpacks_, for short) is a CNCF project that was established jointly by Pivotal and Heroku in 2018. 
They are an evolution of the Cloud Foundry and Heroku buildpacks that have existed since roughly 2011. 
In contrast to the original buildpacks that ere tightly coupled with their respective platforms (Cloud Foundry and Heroku), the CNB project provides a standalone, standardized way to build OCI images that can be published to any OCI-compliant container registry and run on any OCI-compliant runtime platform, such as Kubernetes.

The CNB project provides an opinionated, structured way to build images through a set of APIs and a reference implementation of the orchestration logic. 
Within the CNB ecosystem, various implementations of the Platform and Buildpack API have been developed by different organizations. 
Any tool that implements the Platform API can be used by end users or by CI toolchains to produce images. 
Any module that implements the Buildpack API can be used to produce specific layers for OCI images. 
The platform is the end-user tool, and the buildpack is the framework-specific module. 
You can roughly associate platforms with the docker CLI and docker Daemon, which know how to execute a Dockerfile, and buildpacks with the logic inside a particular Dockerfile, which specifies the base images and the framework-specific logic. 
With CNB, however, we can overcome the challenges of Dockerfiles. 
Rather than write your own Dockerfile logic for each app or category of apps, you can use well-established community or commercial builpacks. 
These builpacks will by and large incorporate best practices for security an efficiency. 
In addition, CNB produces images with well thought-out layers that are not as sensitive to ordering as the layers in a Dockerfile build. 
By decoupling the platform from the orchestration logic and buildpacks, CNB has also made possible an ecosystem of platforms that fit different use cases. 
In these labs, we will explore two such platforms; the `pack` CLI and CNB-support in the Spring Boot Maven Plugin.

Paketo Buildpacks are an evolution of the Cloud Foundry buildpacks.
Set the default builder to use Paketo Buildpacks.
Note: you can run this command even if the `docker build` is still running as it will execute in the second terminal window.
```execute-2
pack config default-builder paketobuildpacks/builder:base
```

Use the `pack` CLI to build an image for the `blueorgreenservice`. 
Note: you can run this command even if the `docker build` is still running as it will execute in the second terminal window.
```execute-2
pack build blueorgreenservice:pk -p blueorgreenservice
```

List the images you have created so far:
```execute-1
docker images | grep blueorgreenservice
```

If both `docker build` and `pack build` have finished running, your output will look like this.
```
blueorgreenservice         df               ed51ed0f4612   8 minutes ago   289MB
blueorgreenservice         pk               adafa746205d   41 years ago    288MB
```

You can use the `docker history` command to get some more information about the first image.
Notice that you can see each layer of the runtime image (from the second build stage).
```execute-1
docker history blueorgreenservice:df
```

You can use the `pack image inspect` command to get some more information about the pack-built image.
```execute-2
pack inspect blueorgreenservice:pk
```

With Cloud Native Buildpacks, you can see precise information about the base image and buildpacks used for the build (akin to the first build stage in our Dockerfile), as well as the base image and start command in the runtime image (akin to the second build stage in our Dockerfile).

You can also inspect and compare the images using a tool called `dive`. 
After running the command below, type `Tab`, `Ctrl-U`, `Tab`. 
This configures the right-hand column (layer conents) to show only changes since the last layer). 
Next, use the down arrow to move down the list of layers on the left until you find the layer that adds the `app.jar` file to the runtime image.
```execute-1
dive blueorgreenservice:df
```

Do the same with the Paketo-built image. 
In this case you will see the Java application was exploded, which makes for faster startup time. 
The blueorgreenservice is quite old; with newer Java applications that use Spring Boot 2.3.0 and above, the exploded files would also be organized into multiple layers, separating files that change infrequently (e.g. Spring Boot base libraries) and files that change more frequently (e.g. your code). 
This makes it faster to rebuild images and publish images updates to container registries. 
In general, the layers in this image are more thoughtfully and consistently organized. 
The Paketo Java Buildpack also contributes a Memory Calculator to the launch layer, which optimizes memory settings when the application is run.
```execute-2
dive blueorgreenservice:pk
```

Exit `dive` in both terminals.
```execute-all
<ctrl+c>
```

Use pack to build images for the remaining Color Application services. 
This will take a few minutes since it is the first build for each.
You can execute the following two blocks of commands at the same time so they run in parallel in both terminal windows.
```execute-1
pack build blueorgreenfrontend:pk -p blueorgreenfrontend
pack build blueorgreengateway:pk -p blueorgreengateway
```

```execute-2
pack build authgateway:pk -p authgateway
pack build eureka:pk -p eureka
```

Since the Eureka-Server app is newer, you can use dive to observe some additional optimizations that Paketo will automatically introduce. 
In addition, you can explore some of the possible configurations with the Paketo Java Builpacks. 
Run the following command to re-build the image for the Eureka-Server app using Java 16 (rather than the default 11) and an additional  environment variable that will set a label in the image. 
Notice that the re-build is faster since the CNB project makes efficient use of caching.
```execute-1
pack build eureka:pk -p eureka -e BP_JVM_VERSION=16.* -e BP_OCI_TITLE="Discovery Server"
```

Now use `dive` to explore the layers of the eureka image. 
Again, type `Tab`, `Ctrl-U`, `Tab` to see only layer changes, then scroll down on the list of layers until you find the application layers. 
Since this app is based on a newer version of Spring Boot, you will see the aditional optimization that is automatically applied by the Paketo Java Buildpack, namely to organize the application files into different layers based on the likelihood of the layers to change. 
The layer that is most likely to change (the code) is now kilobytes rather than megabytes.
```execute-1
dive eureka:pk
```

You can learn more about the Paketo Java Buildpack [here](https://github.com/paketo-buildpacks/java)

## Publish images to registry

In order to deploy these images to Kubernetes, Kubernetes must be able to "pull" them. 
Kubernetes cannot access them from the local Docker daemon. 
It can, however, pull them from a container registry that is network-accessible.

A local private container registry is available in this workshop environment.
For convenience, its address is saved in an environment variable. 
You can see it by running the following command.
```execute-1
echo $REGISTRY_HOST
```

Publish the images to the container registry.
```execute-1
docker tag eureka:pk $REGISTRY_HOST/color-app/eureka
docker push $REGISTRY_HOST/color-app/eureka

docker tag blueorgreenservice:pk $REGISTRY_HOST/color-app/blueorgreenservice
docker push $REGISTRY_HOST/color-app/blueorgreenservice

docker tag blueorgreenfrontend:pk $REGISTRY_HOST/color-app/blueorgreenfrontend
docker push $REGISTRY_HOST/color-app/blueorgreenfrontend

docker tag blueorgreengateway:pk $REGISTRY_HOST/color-app/blueorgreengateway
docker push $REGISTRY_HOST/color-app/blueorgreengateway

docker tag authgateway:pk $REGISTRY_HOST/color-app/authgateway
docker push $REGISTRY_HOST/color-app/authgateway
```

##Validate that the containers are in the registry
```execute-1
skopeo list-tags docker://$REGISTRY_HOST/color-app/eureka
```

```execute-1
skopeo list-tags docker://$REGISTRY_HOST/color-app/blueorgreenservice
```

```execute-1
skopeo list-tags docker://$REGISTRY_HOST/color-app/blueorgreenfrontend
```

```execute-1
skopeo list-tags docker://$REGISTRY_HOST/color-app/blueorgreengateway
```

```execute-1
skopeo list-tags docker://$REGISTRY_HOST/color-app/authgateway
```